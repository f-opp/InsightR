#### rpart - Decision Tree

Decision tree algorithms map data in a hierarchical binary tree structure. Decision tree algorithms can be used for both supervised learning of regression and classification tasks. Decision trees successively divide the value range into orthogonal subdomains.[1][3][4]

#### Characteristics
| Advantages                                                                                           | Disadvantages                                                                                                                |
|------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------|
| Particularly suitable for classification tasks, straight forward and easy to understand approach [2][4] | Accuracy depending on selected parameters, susceptibility to irrelevant data,  resource consumption depending on the problem [2][4]|

---
##### References
* [1] Alpaydin, E. (2010), Introduction to machine learning, Adaptive computation and machine learning, 2nd ed., MIT Press, Cambridge, Mass.
* [2] Hastie, T., Tibshirani, R. and Friedman, J.H. (2009), The elements of statistical learning: Data mining, inference, and prediction, Springer series in statistics, Second edition, Springer, New York.
* [3] James, G., Witten, D., Hastie, T. and Tibshirani, R. (2013), An Introduction to Statistical Learning: With Applications in R, Springer texts in statistics, Vol. 103, Springer, New York, NY.
* [4] Kotsiantis, S.B. (2007), “Supervised machine learning: A review of classification techniques”, Informatica, Vol. 31 No. 3, 249-268.

